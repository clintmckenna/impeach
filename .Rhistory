tm_map(PlainTextDocument)
text
# create wordcloud
wordcloud(text)
# create term document matrix
tdm <- text
# create wordcloud
wordcloud(dm
# create wordcloud
wordcloud(tdm
# create term document matrix
tdm <- text
# create term document matrix
tdm <- TermDocumentMatrix(text)
library(tm)
library(wordcloud)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
# create term document matrix
tdm <- TermDocumentMatrix(text)
?TermDocumentMatrix
text
text[[1]]
text[[2]]
wordcloud(text)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
library(tm)
library(wordcloud)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
wordcloud(text)
wordcloud(text,
max.words = 50)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(VectorSource(text))
wordcloud(text,
max.words = 50)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(VectorSource(text))
wordcloud(text,
max.words = 100)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
wordcloud(text,
max.words = 100)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(DataframeSource(as.matrix(text)))
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
library(tm)
library(wordcloud)
# convert text to a corpus
text <- Corpus(DataframeSource(as.matrix(text)))
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(DataframeSource(as.matrix(text)))
# convert text to a corpus
text <- tm::Corpus(DataframeSource(as.matrix(text)))
# prepare a dataframe
text <- data.frame(
doc_id = length(text),
text = text)
text
# convert text to a corpus
text <- Corpus(DataframeSource(as.matrix(text)))
# convert text to a corpus
text <- Corpus(DataframeSource(text))
text
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
wordcloud(text,
max.words = 100)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
# prepare a dataframe
text <- data.frame(
doc_id = length(text),
text = text)
head(text)
# convert text to a corpus
text <- Corpus(DataframeSource(text))
wordcloud(text,
max.words = 100)
# convert text to a corpus
text <- Corpus(DataframeSource(text))
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
# prepare a dataframe
text <- data.frame(
doc_id = length(text),
text = text)
head(text)
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(DataframeSource(text))
# convert text to a corpus
text <- Corpus(VectorSource(text))
text
text[[1]]
text[[2]]
text[1]
text[2]
text[3]
text[4]
text[5]
text[:]
text[[""]]
text[[:]]
text[[]]
text
text[[23]]
text[[22]]
text[[11]]
text[[11]]$content
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
text
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
# tm_map(removeWords, stopwords('english')) %>%
# tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
text
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation)
text
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers)
text
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)
text
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
# tm_map(removeWords, stopwords('english')) %>%
# tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
text
# lots of the responses are repeated, so just get the unique entries
text <- rounds$response %>%
unique()
head(text)
library(tm)
library(wordcloud)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)
wordcloud(text,
max.words = 100)
text
text[[1]]
text[[22]]
text[[22]]$content
# create term document matrix
tdm <- TermDocumentMatrix(text)
wordcloud(tdm,
max.words = 100)
tdmMatrix <- as.matrix(tdm)
tdm <- TermDocumentMatrix(text)
tdmMatrix <- as.matrix(tdm)
words <- sort(rowSums(tdmMatrix), decreasing=TRUE)
datMatrix <- data.frame(word = names(words),
wordcloud(tdm,
max.words = 100)
wordcloud(tdm,
max.words = 100)
tdm <- TermDocumentMatrix(text)
tdmMatrix <- as.matrix(tdm)
words <- sort(rowSums(tdmMatrix), decreasing=TRUE)
datMatrix <- data.frame(word = names(words), freq=words)
wordcloud(tdm,
max.words = 100)
words
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower) %>%
tm_map(removeWords, stopwords('english'))
text
text[[2]]
text[[22]]
text[[21]]
# create term document matrix
tdm <- TermDocumentMatrix(text)
tdmMatrix <- as.matrix(tdm)
wordcloud(tdmMatrix,
max.words = 100)
wordcloud(text,
max.words = 100)
words <- sort(rowSums(tdmMatrix), decreasing=TRUE)
datMatrix <- data.frame(word = names(words), freq=words)
wordcloud(datMatrix$word,
max.words = 100)
wordcloud(datMatrix$word,
max.words = 10)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq)
datMatrix$word
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
scale=c(3.5,0.25)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
scale=c(1.5,0.25)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
scale=c(2.5,0.25)
)
View(datMatrix)
View(datMatrix)
View(datMatrix)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(2.5,0.25)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(3.5,0.25)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(4.5,0.25)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(2.5,0.1)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(3, 0.1)
)
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
scale=c(3.5, 0.1)
)
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
scale=c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color=brewer.pal(9,"Reds")[(4:8)]
scale=c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color=brewer.pal(9,"Reds")[(4:8)],
scale=c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color=brewer.pal(9,'Blues')[(4:8)],
scale=c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color=brewer.pal(5, 'Blues')[(4:8)],
scale=c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(5, 'Blues'),
scale = c(3.5, 0.1))
brewer.pal(5, 'Blues')
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(4:8)],
scale = c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:7)],
scale = c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(6:9)],
scale = c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:9)],
scale = c(3.5, 0.1))
# print wordcloud
wordcloud(
words = datMatrix$word,
max.words = 100,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:9)],
rot.per=0.15,
scale = c(3.5, 0.1))
# print and save wordcloud
w <- wordcloud(
words = datMatrix$word,
max.words = Inf,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:9)],
rot.per=0.15,
scale = c(3.5, 0.1))
w
# print and save wordcloud
png('../figures/wordcloud.png', units="in", width=10, height=10, res=750)
wordcloud(
words = datMatrix$word,
max.words = Inf,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:9)],
rot.per=0.15,
scale = c(3.5, 0.1))
dev.off()
library(tm)
library(wordcloud)
# convert text to a corpus
text <- Corpus(VectorSource(text))
# do some basic cleaning of text
text <- text %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower) %>%
tm_map(removeWords, stopwords('english'))
# create term document matrix
tdm <- TermDocumentMatrix(text)
tdmMatrix <- as.matrix(tdm)
words <- sort(rowSums(tdmMatrix), decreasing=TRUE)
datMatrix <- data.frame(word = names(words), freq = words)
# print and save wordcloud
png('../figures/wordcloud.png', units="in", width=6, height=6, res=750)
wordcloud(
words = datMatrix$word,
max.words = Inf,
freq = datMatrix$freq,
min.freq = 1,
random.order = FALSE,
color = brewer.pal(9, 'Blues')[(5:9)],
rot.per=0.15,
scale = c(3.5, 0.1))
dev.off()
